#!/usr/bin/env python3
"""
GENERADOR DE CAPA 3: PROBLEMATIZACI√ìN CONTEMPOR√ÅNEA
====================================================

Genera las 19 problematizaciones (1000-1500 palabras) que conectan
los conceptos geneal√≥gicos de CAPA 2 con presente algor√≠tmico.

Dependencias:
- CAPA0: TSR101-120QUOTES.md (fragmentos fundacionales)
- CAPA1: Bibliograf√≠a verificada
- CAPA2: Genealog√≠as conceptuales
- GLOSARIO_CICLOPE.json

Uso:
    python generar_capa3.py --modelo claude --tsr 102
    python generar_capa3.py --modelo sonar --all
    python generar_capa3.py --validar-antes
"""

import json
import os
from pathlib import Path
from datetime import datetime
from typing import Dict, List

# ============================================================================
# CONFIGURACI√ìN
# ============================================================================

GLOSARIO_PATH = Path("config/GLOSARIO_CICLOPE.json")
METADATOS_PATH = Path("config/METADATOS_PROYECTO.json")
CAPAS_DIR = Path("capas")

CAPA0_PATH = CAPAS_DIR / "CAPA0_semilla" / "TSR101-120QUOTES.md"
CAPA1_PATH = CAPAS_DIR / "CAPA1_bibliografia" / "TSR_CAPA1_FINAL.json"
CAPA2_PATH = CAPAS_DIR / "CAPA2_genealogia" / "TSR_CAPA2_FINAL.json"

OUTPUT_PATH = CAPAS_DIR / "CAPA3_problematizacion" / "TSR_CAPA3_FINAL.json"

# ============================================================================
# PROMPT TEMPLATE PARA CAPA 3
# ============================================================================

PROMPT_CAPA3_TEMPLATE = """
# TAREA: Genera la PROBLEMATIZACI√ìN CONTEMPOR√ÅNEA de TSR{tsr_id}

## CONTEXTO PREVIO (CAPAS ANTERIORES)

### CAPA 0: Fragmento fundacional
{fragmento_inicial}

### CAPA 2: Genealog√≠a del concepto
{genealogia_resumen}

## TU TAREA AHORA (CAPA 3)

Escribe la **problematizaci√≥n contempor√°nea** del concepto, conect√°ndolo con:
- Inteligencia Artificial (LLMs, autor√≠a algor√≠tmica, generaci√≥n autom√°tica)
- NFT y blockchain (arte digital, tokenizaci√≥n, escasez programada)
- Plataformas digitales (redes sociales, algoritmos, econom√≠a atenci√≥n)
- Cultura visual algor√≠tmica (deepfakes, filtros, realidad aumentada)

## ESTRUCTURA REQUERIDA (1000-1500 palabras)

### 1. APERTURA TRANSICIONAL (100-150 palabras)
- Retoma el concepto de CAPA 2
- Plantea la tensi√≥n con el presente algor√≠tmico
- Formula pregunta inicial que no se responder√° del todo

**Ejemplo para TSR102 (Aura):**
"La reproductibilidad t√©cnica que Benjamin diagnostic√≥ en 1936 se ha radicalizado: 
ya no reproducimos copias f√≠sicas, sino que generamos infinitas variaciones sint√©ticas. 
¬øQu√© es el aura cuando la 'manifestaci√≥n irrepetible de una lejan√≠a' puede ser 
programada mediante algoritmos? Los NFT prometen resucitar el aura mediante 
escasez criptogr√°fica, pero ¬øno es precisamente esa escasez una simulaci√≥n del 
aura que Benjamin declar√≥ muerta?"

### 2. PROBLEMATIZACI√ìN EN PRESENTE (600-900 palabras)

Desarrolla 3-4 problematizaciones espec√≠ficas. Por ejemplo:

**A) IA y autor√≠a algor√≠tmica**
- ChatGPT, Claude, Midjourney: ¬øqui√©n es autor?
- Funci√≥n-autor (Foucault) en era de coautor√≠a m√°quina-humano
- Contratos que especifican "texto humano sin IA": ¬øqu√© defienden?

**B) NFT y econom√≠a del arte digital**
- Escasez programada vs. reproductibilidad infinita
- Aura como metadata (certificado blockchain)
- Beeple, Grimes, artistas cripto: ¬øresucitan aura o la parodian?

**C) Plataformas y econom√≠a atencional**
- TikTok, Instagram: fragmentaci√≥n vs. totalidad
- Algoritmos de recomendaci√≥n como nuevos "archivos" foucaultianos
- ¬øQu√© cuenta como conocimiento v√°lido en feeds personalizados?

**D) Deepfakes y verdad sint√©tica**
- Indistinguibilidad entre real y generado
- Epistemes algor√≠tmicas: ¬øqu√© reg√≠menes de verdad producen?
- Post-verdad como condici√≥n epist√©mica, no solo pol√≠tica

### 3. RESONANCIA CON REFLEJOS H√çBRIDOS (100-150 palabras)
- Conecta con el universo narrativo/visual RH
- Identidades fragmentadas, archivos generativos
- C√≠clope como m√©todo de visi√≥n situada

### 4. CIERRE ABIERTO (100-150 palabras)
- NO cierres con respuestas definitivas
- Plantea preguntas adicionales
- Abre hacia aplicaci√≥n pedag√≥gica (CAPA 6)

**Ejemplo de cierre abierto:**
"Si la educaci√≥n reproduce estructuras de poder mediante certificaciones 
que validan qui√©n puede hablar, ¬øc√≥mo cambian esas estructuras cuando 
los estudiantes co-escriben con IA? ¬øQu√© significa 'voz propia' en un 
ecosistema donde la escritura es negociaci√≥n con sistemas probabil√≠sticos? 
Las instituciones educativas responden prohibiendo IA o exigiendo 
declaraciones de 'trabajo humano'. Pero esa respuesta revela que no saben 
c√≥mo leer textos h√≠bridos. Y ah√≠ es donde la lectura de segundo orden 
se vuelve urgente."

## INSTRUCCIONES CR√çTICAS

### TONO Y M√âTODO
- ‚úÖ Espa√±ol mexicano (no rioplatense, no neutro acad√©mico)
- ‚úÖ M√©todo socr√°tico: preguntas que arden, no respuestas que cierran
- ‚úÖ Cr√≠tico sin ser nihilista: exponer problemas sin proponer soluciones f√°ciles
- ‚úÖ Interpela al lector: "¬øTe has preguntado...?", "Observa lo que pasa cuando..."
- ‚ùå NO usar bullet points ni numeraci√≥n visible
- ‚ùå NO cerrar con conclusiones definitivas
- ‚ùå NO mencionar "en conclusi√≥n", "para finalizar", etc.

### VALIDACI√ìN TERMINOL√ìGICA
Estos t√©rminos deben usarse seg√∫n el GLOSARIO_CICLOPE.json:
{terminos_clave}

Si usas un t√©rmino con m√∫ltiples definiciones (ej: "fragmento"), 
DEBES especificar cu√°l definici√≥n activas:
- ‚úÖ "El fragmento (seg√∫n Schlegel, con promesa de totalidad)..."
- ‚úÖ "El fragmento blanchotiano (sin s√≠ntesis posible)..."
- ‚ùå "El fragmento..." (sin especificar cu√°l definici√≥n)

### CITAS Y REFERENCIAS
- Usa citas de CAPA 1 cuando sea relevante
- Formato: [Autor, a√±o] inline
- NO inventes citas ni autores
- Puedes mencionar eventos actuales 2024-2026

## EXTENSI√ìN
- M√≠nimo: 1000 palabras
- M√°ximo: 1500 palabras
- Ideal: 1200 palabras

## AHORA GENERA LA PROBLEMATIZACI√ìN PARA TSR{tsr_id}
"""

# ============================================================================
# FUNCIONES AUXILIARES
# ============================================================================

def cargar_json(path: Path) -> Dict:
    """Carga archivo JSON"""
    with open(path, 'r', encoding='utf-8') as f:
        return json.load(f)

def cargar_fragmento_inicial(tsr_id: int) -> str:
    """Extrae el fragmento fundacional de CAPA 0"""
    # TODO: Implementar parser de TSR101-120QUOTES.md
    # Por ahora retorna placeholder
    return f"[Fragmento fundacional de TSR{tsr_id}]"

def cargar_genealogia(tsr_id: int, capa2_data: Dict) -> str:
    """Extrae resumen de la genealog√≠a de CAPA 2"""
    for tsr in capa2_data.get('estructura', []):
        if tsr.get('tsr') == tsr_id:
            genealogia = tsr.get('genealogia', '')
            # Extraer primeros 300 caracteres como resumen
            return genealogia[:300] + "..." if len(genealogia) > 300 else genealogia
    return "[Genealog√≠a no encontrada]"

def generar_prompt_capa3(tsr_id: int, glosario: Dict, capa2: Dict) -> str:
    """Genera el prompt completo para un TSR espec√≠fico"""
    
    fragmento = cargar_fragmento_inicial(tsr_id)
    genealogia = cargar_genealogia(tsr_id, capa2)
    
    # Extraer t√©rminos clave relevantes para este TSR
    terminos_clave = glosario['validacion_coherencia']['terminos_clave_rastreados']
    terminos_str = "\n".join([f"- {t}" for t in terminos_clave])
    
    return PROMPT_CAPA3_TEMPLATE.format(
        tsr_id=tsr_id,
        fragmento_inicial=fragmento,
        genealogia_resumen=genealogia,
        terminos_clave=terminos_str
    )

def validar_extensio(texto: str) -> tuple[bool, int]:
    """Valida que la extensi√≥n est√© en rango 1000-1500 palabras"""
    palabras = len(texto.split())
    valido = 1000 <= palabras <= 1500
    return valido, palabras

def guardar_resultado(resultados: Dict, output_path: Path):
    """Guarda los resultados en JSON"""
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(resultados, f, indent=2, ensure_ascii=False)
    
    print(f"\nüíæ Resultados guardados en: {output_path}")

# ============================================================================
# GENERADOR PRINCIPAL
# ============================================================================

def generar_capa3_tsr(
    tsr_id: int,
    modelo: str,
    glosario: Dict,
    capa2: Dict
) -> Dict:
    """
    Genera la problematizaci√≥n de un TSR espec√≠fico.
    
    Args:
        tsr_id: N√∫mero del TSR (102-120)
        modelo: 'claude' o 'sonar'
        glosario: Diccionario del glosario cargado
        capa2: Datos de CAPA 2
    
    Returns:
        Dict con la problematizaci√≥n generada
    """
    print(f"\nüìù Generando CAPA 3 para TSR{tsr_id}...")
    
    # Generar prompt
    prompt = generar_prompt_capa3(tsr_id, glosario, capa2)
    
    # TODO: Integrar con API de Claude o Sonar
    # Por ahora, placeholder
    problematizacion = f"[Problematizaci√≥n de TSR{tsr_id} generada con {modelo}]"
    
    # Validar extensi√≥n
    valida, num_palabras = validar_extensio(problematizacion)
    
    if not valida:
        print(f"‚ö†Ô∏è  ADVERTENCIA: TSR{tsr_id} tiene {num_palabras} palabras (esperado: 1000-1500)")
    
    return {
        "tsr": tsr_id,
        "problematizacion": problematizacion,
        "num_palabras": num_palabras,
        "validacion_extension": valida,
        "modelo_usado": modelo,
        "fecha_generacion": datetime.now().isoformat()
    }

# ============================================================================
# CLI
# ============================================================================

def main():
    import argparse
    
    parser = argparse.ArgumentParser(
        description='Genera CAPA 3 (Problematizaci√≥n contempor√°nea) del proyecto C√≠clope TSR'
    )
    parser.add_argument('--modelo', choices=['claude', 'sonar'], default='claude',
                       help='Modelo de LLM a usar')
    parser.add_argument('--tsr', type=int, help='TSR espec√≠fico a generar (102-120)')
    parser.add_argument('--all', action='store_true', help='Generar todos los TSR')
    parser.add_argument('--validar-antes', action='store_true',
                       help='Validar coherencia de CAPA 2 antes de generar')
    parser.add_argument('--output', help='Ruta de salida personalizada')
    
    args = parser.parse_args()
    
    # Cargar dependencias
    print("üìñ Cargando dependencias...")
    glosario = cargar_json(GLOSARIO_PATH)
    metadatos = cargar_json(METADATOS_PATH)
    capa2 = cargar_json(CAPA2_PATH)
    
    print("‚úÖ Dependencias cargadas\n")
    
    # Validar CAPA 2 si se solicita
    if args.validar_antes:
        print("üîç Validando coherencia de CAPA 2...")
        os.system("python validar_coherencia_capas.py --capa CAPA2 --all")
        print()
    
    # Determinar rango de TSR a generar
    if args.all:
        tsr_range = range(102, 121)
    elif args.tsr:
        tsr_range = [args.tsr]
    else:
        print("‚ùå ERROR: Especifica --tsr N o --all")
        return
    
    # Generar problematizaciones
    resultados = {
        "metadata": {
            "capa": "CAPA 3: Problematizaci√≥n contempor√°nea",
            "fecha_generacion": datetime.now().isoformat(),
            "total_tsr": len(tsr_range),
            "modelo": args.modelo
        },
        "estructura": []
    }
    
    for tsr_id in tsr_range:
        resultado_tsr = generar_capa3_tsr(tsr_id, args.modelo, glosario, capa2)
        resultados["estructura"].append(resultado_tsr)
    
    # Guardar resultados
    output_path = Path(args.output) if args.output else OUTPUT_PATH
    guardar_resultado(resultados, output_path)
    
    # Estad√≠sticas finales
    total_palabras = sum(r['num_palabras'] for r in resultados['estructura'])
    promedio = total_palabras / len(resultados['estructura'])
    
    print(f"\n{'='*60}")
    print(f"ESTAD√çSTICAS FINALES")
    print(f"{'='*60}")
    print(f"TSR generados: {len(resultados['estructura'])}")
    print(f"Palabras totales: {total_palabras:,}")
    print(f"Promedio por TSR: {promedio:.0f} palabras")
    print(f"{'='*60}\n")

if __name__ == '__main__':
    main()
