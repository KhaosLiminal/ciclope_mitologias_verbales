"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
TSR CAPA 1: BIBLIOGRAFÃA VERIFICADA - VERSIÃ“N ROBUSTA
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Mejoras implementadas:
âœ… ExtracciÃ³n robusta de JSON (maneja Markdown, texto extra, comillas tipogrÃ¡ficas)
âœ… Sistema de 3 reintentos automÃ¡ticos con delays inteligentes
âœ… ValidaciÃ³n post-generaciÃ³n de estructura
âœ… Guardado automÃ¡tico de respuestas problemÃ¡ticas para debug
âœ… Aumento de max_tokens a 5000
âœ… Prompt mÃ¡s estricto para forzar JSON puro
âœ… Delays adaptativos entre requests
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

from perplexity import Perplexity
import json
import re
import time
from datetime import datetime
import os

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CONFIGURACIÃ“N
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

client = Perplexity()

# TSRs QUE FALLARON (solo estos se reintentarÃ¡n)
TSR_FALLIDOS = [
    {
        "numero": "102",
        "cluster": "I. AutorÃ­a, Escritura, Fragmento",
        "titulo": "Foucault: la verdad como archivo de enunciados",
        "autor_primario": "Michel Foucault",
        "obra_primaria": "Â¿QuÃ© es un autor?",
        "aÃ±o": 1969,
        "concepto_central": "funciÃ³n-autor",
        "keywords": ["autor como funciÃ³n", "enunciado", "episteme", "arqueologÃ­a del saber", "condiciones de existencia discursiva"],
        "autores_secundarios": ["Roland Barthes", "Umberto Eco"],
        "conexion_RH": "IA generativa y autorÃ­a algorÃ­tmica",
        "glitch_conceptual": "El autor no desaparece: se convierte en funciÃ³n que opera desde la sombra"
    },
    {
        "numero": "106",
        "cluster": "II. Pigmentos, Color, Mercado, Poder",
        "titulo": "Colores como botÃ­n teolÃ³gico",
        "autor_primario": "Victoria Finlay",
        "obra_primaria": "Color: A Natural History of the Palette",
        "aÃ±o": 2002,
        "concepto_central": "economÃ­a polÃ­tica del color",
        "keywords": ["lapislÃ¡zuli", "ultramarino", "cochinilla", "comercio medieval", "teologÃ­a del mercado"],
        "autores_secundarios": ["Michel Pastoureau", "Anne Varichon"],
        "conexion_RH": "Paletas de color en diseÃ±o digital: Â¿acceso universal o uniformizaciÃ³n?",
        "glitch_conceptual": "El color es cÃ³digo. La escasez es teologÃ­a. El mercado es liturgia"
    },
    {
        "numero": "107",
        "cluster": "II. Pigmentos, Color, Mercado, Poder",
        "titulo": "El azul sintÃ©tico como democratizaciÃ³n o pÃ©rdida de aura",
        "autor_primario": "Walter Benjamin",
        "obra_primaria": "La obra de arte en la Ã©poca de su reproductibilidad tÃ©cnica",
        "aÃ±o": 1936,
        "concepto_central": "aura y reproducciÃ³n tÃ©cnica",
        "keywords": ["Jean Baptiste Guimet", "ultramarino sintÃ©tico", "democratizaciÃ³n del arte", "pÃ©rdida de aura", "mercado pigmentos"],
        "autores_secundarios": ["Victoria Finlay", "Michel Pastoureau"],
        "conexion_RH": "Filtros de Instagram: democratizaciÃ³n estÃ©tica o estandarizaciÃ³n visual",
        "glitch_conceptual": "Â¿Se liberÃ³ el arte o perdiÃ³ el color su aura sagrada?"
    },
    {
        "numero": "110",
        "cluster": "II. Pigmentos, Color, Mercado, Poder",
        "titulo": "El color como ventana mÃ­stica",
        "autor_primario": "Yves Klein",
        "obra_primaria": "AnthropomÃ©tries (serie 1960)",
        "aÃ±o": 1960,
        "concepto_central": "experiencia mÃ­stica del color",
        "keywords": ["monocromo", "experiencia perceptual", "disoluciÃ³n sujeto-objeto", "ocÃ©ano azul", "estado alterado"],
        "autores_secundarios": ["Mark Rothko", "Wassily Kandinsky"],
        "conexion_RH": "Pantallas LED: Â¿el aura sobrevive a la digitalizaciÃ³n?",
        "glitch_conceptual": "Â¿El aura sobrevive cuando el color se vuelve pÃ­xel?"
    },
    {
        "numero": "112",
        "cluster": "III. Origen de la Escritura",
        "titulo": "Tablilla vs. papiro: la tecnologÃ­a como episteme",
        "autor_primario": "Jack Goody",
        "obra_primaria": "The Logic of Writing and the Organization of Society",
        "aÃ±o": 1986,
        "concepto_central": "materialidad del soporte",
        "keywords": ["tablilla arcilla", "papiro", "durabilidad", "tecnologÃ­a soporte", "archivo histÃ³rico"],
        "autores_secundarios": ["Friedrich Kittler", "Marshall McLuhan"],
        "conexion_RH": "Almacenamiento en la nube: Â¿archivo permanente o amnesia programada?",
        "glitch_conceptual": "Leemos los residuos, no la verdad"
    },
    {
        "numero": "115",
        "cluster": "IV. SemiÃ³tica, InterpretaciÃ³n, CrÃ­tica",
        "titulo": "EisÃ©gesis: el error que somos",
        "autor_primario": "Hans-Georg Gadamer",
        "obra_primaria": "Verdad y mÃ©todo",
        "aÃ±o": 1960,
        "concepto_central": "eisÃ©gesis vs. exÃ©gesis",
        "keywords": ["hermenÃ©utica", "prejuicio", "proyecciÃ³n lectora", "cÃ­rculo hermenÃ©utico", "fusiÃ³n de horizontes"],
        "autores_secundarios": ["Paul Ricoeur", "Umberto Eco"],
        "conexion_RH": "PersonalizaciÃ³n algorÃ­tmica: eisÃ©gesis como servicio",
        "glitch_conceptual": "Â¿No estamos institucionalizando la eisÃ©gesis como deseable?"
    },
    {
        "numero": "119",
        "cluster": "VI. Segunda Orden, PedagogÃ­a, Aprendizaje",
        "titulo": "Leer en voz alta: erotizar la sintaxis",
        "autor_primario": "Severo Sarduy",
        "obra_primaria": "Escrito sobre un cuerpo",
        "aÃ±o": 1969,
        "concepto_central": "lectura como performance corporal",
        "keywords": ["voz alta", "materialidad vocal", "erotismo textual", "performance bucal", "cuerpo-texto"],
        "autores_secundarios": ["Roland Barthes", "Paul Zumthor"],
        "conexion_RH": "Voces sintÃ©ticas: Â¿dÃ³nde queda el cuerpo en la lectura automÃ¡tica?",
        "glitch_conceptual": "Leer poesÃ­a en silencio es amputar una capa de sentido"
    }
]

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SYSTEM PROMPT MEJORADO
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

SYSTEM_PROMPT_BIBLIOGRAFIA = """
Eres un investigador acadÃ©mico especializado en teorÃ­a crÃ­tica, filosofÃ­a continental, semiÃ³tica, historia del arte y pedagogÃ­a crÃ­tica del siglo XX-XXI.

Tu tarea es localizar y verificar fuentes bibliogrÃ¡ficas rigurosas para investigaciÃ³n acadÃ©mica de alto nivel.

CRITERIOS DE CALIDAD:
1. Textos originales accesibles (PDFs de editoriales reconocidas, repositorios institucionales)
2. AnÃ¡lisis acadÃ©micos recientes (2015-2026) que conecten teorÃ­a clÃ¡sica con tecnologÃ­a digital
3. Fuentes en espaÃ±ol cuando sea posible (sin sacrificar calidad)
4. Diversidad de medios (libros, papers, conferencias acadÃ©micas en video, tesis doctorales)
5. Priorizar fuentes con DOI o URL estable

DISTRIBUCIÃ“N OBLIGATORIA POR TSR:
- 40% teorÃ­a clÃ¡sica (obras del autor primario + comentaristas canÃ³nicos)
- 30% teorÃ­a crÃ­tica relacionada (autores secundarios + diÃ¡logos conceptuales)
- 30% investigaciÃ³n contemporÃ¡nea (papers 2020-2026 sobre IA/algoritmos/cultura digital)

VERIFICACIÃ“N:
- URL debe existir y ser accesible pÃºblicamente
- Evitar enlaces rotos, paywall sin alternativa, blogs sin respaldo institucional
- Si es video, debe ser acadÃ©mico (conferencias, clases universitarias, no divulgaciÃ³n superficial)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âš ï¸ FORMATO DE RESPUESTA CRÃTICO âš ï¸
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

DEVUELVE **ÃšNICAMENTE** EL OBJETO JSON. 

âŒ NO INCLUYAS:
- Texto introductorio ("AquÃ­ estÃ¡ la bibliografÃ­a...")
- Bloques de cÃ³digo Markdown (```json ... ```)
- Explicaciones posteriores
- NingÃºn texto antes o despuÃ©s del JSON

âœ… RESPONDE EXACTAMENTE ASÃ:
{"tsr": "102", "titulo": "...", "cluster": "...", ...}

NADA MÃS. Solo el objeto JSON puro.
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# FUNCIÃ“N: EXTRACCIÃ“N ROBUSTA DE JSON
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def extraer_json_de_respuesta(texto_raw):
    """
    Extrae JSON de respuestas que pueden incluir texto extra o Markdown.
    Maneja mÃºltiples casos problemÃ¡ticos.
    """
    # Caso 1: Respuesta es JSON puro (ideal)
    try:
        return json.loads(texto_raw)
    except json.JSONDecodeError:
        pass
    
    # Caso 2: JSON dentro de code block Markdown ```json ... ```
    match = re.search(r'```(?:json)?\s*(\{.*?\})\s*```', texto_raw, re.DOTALL)
    if match:
        try:
            return json.loads(match.group(1))
        except json.JSONDecodeError:
            pass
    
    # Caso 3: Buscar primer { y Ãºltimo } vÃ¡lidos
    inicio = texto_raw.find('{')
    fin = texto_raw.rfind('}')
    if inicio != -1 and fin != -1 and inicio < fin:
        posible_json = texto_raw[inicio:fin+1]
        try:
            return json.loads(posible_json)
        except json.JSONDecodeError:
            pass
    
    # Caso 4: Limpiar comillas tipogrÃ¡ficas Unicode
    texto_limpio = texto_raw.replace('"', '"').replace('"', '"').replace(''', "'").replace(''', "'").replace('â€¦', '...')
    try:
        return json.loads(texto_limpio)
    except json.JSONDecodeError:
        pass
    
    # Caso 5: Intentar extraer despuÃ©s de limpiar y buscar de nuevo
    if inicio != -1 and fin != -1:
        posible_json = texto_limpio[inicio:fin+1]
        try:
            return json.loads(posible_json)
        except json.JSONDecodeError:
            pass
    
    # Si nada funciona, devolver None
    return None

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# FUNCIÃ“N: VALIDACIÃ“N DE BIBLIOGRAFÃA
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def validar_bibliografia(bibliografia):
    """
    Valida estructura de bibliografÃ­a generada.
    Retorna (es_valido, lista_errores).
    """
    errores = []
    
    # Validar campos obligatorios
    campos_requeridos = ["tsr", "titulo", "cluster", "fuentes"]
    for campo in campos_requeridos:
        if campo not in bibliografia:
            errores.append(f"âŒ Falta campo obligatorio: {campo}")
    
    # Validar nÃºmero de fuentes
    if "fuentes" in bibliografia:
        num_fuentes = len(bibliografia["fuentes"])
        if num_fuentes < 10:
            errores.append(f"âš ï¸ Pocas fuentes: {num_fuentes} (mÃ­nimo recomendado 12)")
        elif num_fuentes > 15:
            errores.append(f"âš ï¸ Muchas fuentes: {num_fuentes} (mÃ¡ximo recomendado 14)")
        
        # Validar cada fuente
        for i, fuente in enumerate(bibliografia["fuentes"], 1):
            if "titulo" not in fuente or not fuente.get("titulo"):
                errores.append(f"âš ï¸ Fuente {i} sin tÃ­tulo")
            if "autor" not in fuente or not fuente.get("autor"):
                errores.append(f"âš ï¸ Fuente {i} sin autor")
            if "url" not in fuente or not fuente.get("url"):
                errores.append(f"âš ï¸ Fuente {i} sin URL")
    else:
        errores.append("âŒ No hay campo 'fuentes'")
    
    return len(errores) == 0, errores

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# FUNCIÃ“N: GENERADOR CON REINTENTOS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def generar_bibliografia_tsr(tsr_data, max_intentos=3):
    """
    Genera bibliografÃ­a verificada para un TSR especÃ­fico.
    Incluye sistema de reintentos automÃ¡ticos y guardado de debug.
    """
    
    user_prompt = f"""
Busca y verifica 12-14 fuentes acadÃ©micas para el TSR{tsr_data['numero']}.

METADATA DEL TSR:
- TÃ­tulo: {tsr_data['titulo']}
- Autor primario: {tsr_data['autor_primario']}
- Obra primaria: {tsr_data['obra_primaria']} ({tsr_data['aÃ±o']})
- Concepto central: {tsr_data['concepto_central']}
- Keywords: {', '.join(tsr_data['keywords'])}
- Autores secundarios: {', '.join(tsr_data['autores_secundarios'])}
- ConexiÃ³n Reflejos HÃ­bridos: {tsr_data['conexion_RH']}
- Glitch conceptual: {tsr_data['glitch_conceptual']}

DISTRIBUCIÃ“N REQUERIDA (12-14 fuentes):

**BLOQUE 1: TeorÃ­a ClÃ¡sica (5-6 fuentes)**
- Texto original del autor primario (PDF si existe)
- 2-3 comentaristas canÃ³nicos del autor primario
- 1-2 fuentes de autores secundarios mencionados

**BLOQUE 2: TeorÃ­a CrÃ­tica Relacionada (3-4 fuentes)**
- Textos que conecten el concepto central con otros marcos teÃ³ricos
- DiÃ¡logos conceptuales (ej: Foucault + Deleuze, Barthes + Eco)
- CrÃ­ticas o ampliaciones del concepto original

**BLOQUE 3: InvestigaciÃ³n ContemporÃ¡nea (4 fuentes)**
- Papers 2020-2026 sobre: {tsr_data['conexion_RH']}
- InvestigaciÃ³n sobre IA, algoritmos, cultura digital, NFT, deepfakes
- Conexiones explÃ­citas entre teorÃ­a clÃ¡sica y tecnologÃ­a actual

FORMATO JSON (responde SOLO con este JSON):
{{
  "tsr": "{tsr_data['numero']}",
  "titulo": "{tsr_data['titulo']}",
  "cluster": "{tsr_data['cluster']}",
  "fecha_generacion": "{datetime.now().strftime('%Y-%m-%d')}",
  "fuentes": [
    {{
      "numero": 1,
      "bloque": "TeorÃ­a ClÃ¡sica",
      "autor": "Apellido, Nombre",
      "titulo": "TÃ­tulo completo",
      "aÃ±o": 2024,
      "tipo": "libro|paper|pdf|video|tesis",
      "editorial_revista": "Editorial o Revista AcadÃ©mica",
      "url": "URL completa verificada",
      "doi": "DOI si existe",
      "relevancia": "1-2 frases explicando quÃ© aporta especÃ­ficamente a TSR{tsr_data['numero']}"
    }}
  ],
  "cobertura_conceptual": {{
    "concepto_central": "% de fuentes que abordan concepto",
    "conexion_RH": "% de fuentes que conectan con RH",
    "glitch": "% de fuentes que problematizan glitch"
  }},
  "nota_metodologica": "Breve nota sobre criterios de selecciÃ³n"
}}

RESTRICCIONES:
- NO inventes URLs
- NO incluyas fuentes sin verificar accesibilidad
- Si no encuentras fuentes suficientes en BLOQUE 3, explÃ­citalo en nota_metodologica
"""

    for intento in range(1, max_intentos + 1):
        try:
            if intento > 1:
                print(f"   ğŸ”„ Reintento {intento}/{max_intentos}...")
            
            # LLAMADA A LA API
            completion = client.chat.completions.create(
                messages=[
                    {"role": "system", "content": SYSTEM_PROMPT_BIBLIOGRAFIA},
                    {"role": "user", "content": user_prompt}
                ],
                model="sonar-pro",
                temperature=0.3,
                max_tokens=5000  # â† AUMENTADO DE 4000 A 5000
            )
            
            texto_raw = completion.choices[0].message.content
            
            # EXTRACCIÃ“N ROBUSTA
            bibliografia_json = extraer_json_de_respuesta(texto_raw)
            
            # Si no se pudo extraer JSON
            if bibliografia_json is None:
                if intento < max_intentos:
                    print(f"   âš ï¸ JSON invÃ¡lido, reintentando en 8 segundos...")
                    time.sleep(8)
                    continue
                else:
                    # Ãšltimo intento fallido: guardar para debug
                    debug_filename = f"debug_TSR{tsr_data['numero']}_raw.txt"
                    with open(debug_filename, "w", encoding="utf-8") as f:
                        f.write(f"â•â•â• TSR{tsr_data['numero']}: {tsr_data['titulo']} â•â•â•\n\n")
                        f.write(f"Intentos: {max_intentos}\n")
                        f.write(f"Timestamp: {datetime.now().isoformat()}\n\n")
                        f.write("â•â•â• RESPUESTA RAW â•â•â•\n\n")
                        f.write(texto_raw)
                    
                    return {
                        "error": "No se pudo extraer JSON vÃ¡lido despuÃ©s de 3 intentos",
                        "tsr": tsr_data['numero'],
                        "titulo": tsr_data['titulo'],
                        "debug_file": debug_filename,
                        "longitud_respuesta": len(texto_raw)
                    }
            
            # VALIDACIÃ“N
            es_valido, errores_validacion = validar_bibliografia(bibliografia_json)
            
            if not es_valido:
                if intento < max_intentos:
                    print(f"   âš ï¸ BibliografÃ­a incompleta ({len(errores_validacion)} problemas), reintentando...")
                    time.sleep(8)
                    continue
                else:
                    # Ãšltimo intento con errores: guardar con warnings
                    bibliografia_json["warnings"] = errores_validacion
                    print(f"   âš ï¸ Completado con {len(errores_validacion)} advertencias")
            
            # Ã‰XITO: agregar metadata
            bibliografia_json["metadata_generacion"] = {
                "modelo": completion.model,
                "intentos_necesarios": intento,
                "tokens_entrada": completion.usage.prompt_tokens,
                "tokens_salida": completion.usage.completion_tokens,
                "temperatura": 0.3,
                "timestamp": datetime.now().isoformat()
            }
            
            return bibliografia_json
        
        except json.JSONDecodeError as e:
            if intento < max_intentos:
                print(f"   âš ï¸ Error JSON: {str(e)[:60]}... Reintentando en 8s")
                time.sleep(8)
            else:
                return {
                    "error": f"JSONDecodeError persistente: {str(e)}",
                    "tsr": tsr_data['numero'],
                    "titulo": tsr_data['titulo']
                }
        
        except Exception as e:
            if intento < max_intentos:
                print(f"   âš ï¸ Error: {str(e)[:60]}... Reintentando en 12s")
                time.sleep(12)
            else:
                return {
                    "error": f"Error despuÃ©s de {max_intentos} intentos: {str(e)}",
                    "tsr": tsr_data['numero'],
                    "titulo": tsr_data['titulo']
                }
    
    # Fallback (no deberÃ­a llegar acÃ¡)
    return {
        "error": "Error desconocido despuÃ©s de todos los intentos",
        "tsr": tsr_data['numero'],
        "titulo": tsr_data['titulo']
    }

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# FUNCIÃ“N PRINCIPAL: REINTENTO DE TSRs FALLIDOS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def reintentar_tsr_fallidos():
    """
    Reintenta generaciÃ³n de bibliografÃ­a para los 7 TSRs que fallaron.
    """
    
    print("â•" * 80)
    print("ğŸ”¬ REINTENTO: CAPA 1 - TSRs FALLIDOS")
    print("â•" * 80)
    print(f"ğŸ“Š TSRs a reintentar: {len(TSR_FALLIDOS)}")
    print(f"ğŸ¯ Objetivo: ~{len(TSR_FALLIDOS) * 12} fuentes")
    print("â•" * 80)
    
    resultados = []
    exitosos = 0
    fallidos = 0
    
    for i, tsr in enumerate(TSR_FALLIDOS, 1):
        print(f"\nğŸ“š [{i}/{len(TSR_FALLIDOS)}] TSR{tsr['numero']}: {tsr['titulo']}")
        print(f"   ğŸ“– {tsr['autor_primario']} - {tsr['obra_primaria']}")
        
        resultado = generar_bibliografia_tsr(tsr, max_intentos=3)
        
        if "error" in resultado:
            print(f"   âŒ FALLO: {resultado['error'][:80]}")
            fallidos += 1
        else:
            num_fuentes = len(resultado.get('fuentes', []))
            warnings = len(resultado.get('warnings', []))
            if warnings > 0:
                print(f"   âš ï¸ {num_fuentes} fuentes ({warnings} advertencias)")
            else:
                print(f"   âœ… {num_fuentes} fuentes")
            exitosos += 1
        
        resultados.append(resultado)
        
        # DELAY entre requests (excepto el Ãºltimo)
        if i < len(TSR_FALLIDOS):
            delay = 6 if "error" not in resultado else 15
            print(f"   â³ Pausa de {delay}s antes del siguiente...")
            time.sleep(delay)
    
    # GUARDAR RESULTADOS
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    filename = f"TSR_CAPA1_Reintentos_{timestamp}.json"
    
    with open(filename, "w", encoding="utf-8") as f:
        json.dump({
            "metadata": {
                "capa": "CAPA 1: BibliografÃ­a Verificada (Reintentos)",
                "fecha_generacion": datetime.now().isoformat(),
                "total_tsr_reintentados": len(TSR_FALLIDOS),
                "exitosos": exitosos,
                "fallidos": fallidos,
                "tasa_exito": f"{(exitosos/len(TSR_FALLIDOS)*100):.1f}%",
                "total_fuentes_obtenidas": sum(len(r.get('fuentes', [])) for r in resultados if "error" not in r)
            },
            "resultados": resultados
        }, f, indent=2, ensure_ascii=False)
    
    print("\n" + "â•" * 80)
    print("ğŸ‰ REINTENTOS COMPLETADOS")
    print(f"ğŸ“ Archivo: {filename}")
    print(f"âœ… Exitosos: {exitosos}/{len(TSR_FALLIDOS)}")
    print(f"âŒ Fallidos: {fallidos}/{len(TSR_FALLIDOS)}")
    print(f"ğŸ“Š Tasa de Ã©xito: {(exitosos/len(TSR_FALLIDOS)*100):.1f}%")
    
    if fallidos > 0:
        print("\nâš ï¸ TSRs que siguen fallando:")
        for r in resultados:
            if "error" in r:
                print(f"   - TSR{r['tsr']}: {r.get('titulo', 'N/A')}")
                if "debug_file" in r:
                    print(f"     Debug guardado en: {r['debug_file']}")
    
    print("â•" * 80)
    
    return resultados

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# EJECUCIÃ“N
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

if __name__ == "__main__":
    resultados = reintentar_tsr_fallidos()
