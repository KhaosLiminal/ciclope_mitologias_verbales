"""
TSR_CAPA2_Resumenes.py
Genera res√∫menes conceptuales de 150-200 palabras para cada TSR
RUTA CORREGIDA: c√≠clope_en_siete_capas/scripts/
"""

import json
import time
import os
from datetime import datetime
from openai import OpenAI

# ============================================================================
# CONFIGURACI√ìN
# ============================================================================

# API de Perplexity
API_KEY = "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"
client = OpenAI(api_key=API_KEY, base_url="https://api.perplexity.ai")

# Rutas (relativas a la carpeta scripts donde est√° este archivo)
ARCHIVO_ENTRADA = "TSR_CAPA1_FINAL.json"
ARCHIVO_SALIDA = "TSR_CAPA2_Resumenes.json"

# Verificar que estamos en la carpeta correcta
if not os.path.exists(ARCHIVO_ENTRADA):
    print("‚ùå ERROR: No se encuentra TSR_CAPA1_FINAL.json")
    print(f"üìÇ Ubicaci√≥n actual: {os.getcwd()}")
    print(f"üí° Aseg√∫rate de ejecutar desde: c√≠clope_en_siete_capas/scripts/")
    exit(1)

# Par√°metros
MODELO = "sonar-pro"
MAX_TOKENS = 2500
TEMPERATURA = 0.7
DELAY_SEGUNDOS = 6

# ============================================================================
# PROMPT PARA RES√öMENES
# ============================================================================

PROMPT_TEMPLATE = """Eres un te√≥rico literario especializado en teor√≠a cr√≠tica y filosof√≠a contempor√°nea.

**CONTEXTO DEL PROYECTO:**
"Reflejos H√≠bridos" es un universo narrativo que explora identidades fragmentadas, archivos como estructuras generativas, y la tensi√≥n entre materialidad textual y desmaterializaci√≥n digital.

**TSR (Tensor Sem√°ntico-Ret√≥rico) a resumir:**
- **N√∫mero:** {numero_tsr}
- **T√≠tulo:** {titulo}
- **Cluster:** {cluster}

**FUENTES BIBLIOGR√ÅFICAS DISPONIBLES:**
{fuentes}

---

**TAREA:**
Redacta un resumen conceptual de **150-200 palabras exactas** con esta estructura:

**1. CONCEPTO CENTRAL (40-50 palabras)**
Define el concepto te√≥rico principal y su contexto epist√©mico.

**2. APORTACI√ìN DEL AUTOR PRIMARIO (40-50 palabras)**
Explica la tesis central y la innovaci√≥n conceptual del autor principal citado en el TSR.

**3. DI√ÅLOGO CON AUTORES SECUNDARIOS (30-40 palabras)**
Establece convergencias y tensiones con otros te√≥ricos de las fuentes bibliogr√°ficas.

**4. CONEXI√ìN CON REFLEJOS H√çBRIDOS (30-40 palabras)**
Vincula el concepto con el universo narrativo: identidades fragmentadas, archivos como estructuras generativas, o materialidad/desmaterializaci√≥n textual.

---

**REQUISITOS:**
- Vocabulario acad√©mico preciso
- Citas conceptuales (sin comillas, integradas al texto)
- Tono anal√≠tico y denso
- NO uses enumeraci√≥n expl√≠cita (1, 2, 3, 4)
- Flujo continuo entre secciones
- Total: 150-200 palabras

**FORMATO DE SALIDA:**
Redacta un solo p√°rrafo cohesionado que integre las cuatro secciones de manera org√°nica.
"""

# ============================================================================
# FUNCIONES
# ============================================================================

def cargar_tsr_capa1():
    """Carga los TSRs de CAPA 1"""
    print(f"\nüìÇ Cargando: {ARCHIVO_ENTRADA}")
    
    with open(ARCHIVO_ENTRADA, 'r', encoding='utf-8') as f:
        datos = json.load(f)
    
    # Extraer TSRs seg√∫n estructura
    tsr_list = []
    
    if 'clusters' in datos:
        for cluster_nombre, tsrs in datos['clusters'].items():
            for tsr in tsrs:
                tsr['cluster'] = cluster_nombre
                tsr_list.append(tsr)
    elif 'resultados' in datos:
        tsr_list = datos['resultados']
    
    # Ordenar por n√∫mero de TSR
    tsr_list.sort(key=lambda x: int(x.get('tsr', 0)))
    
    print(f"   ‚úÖ {len(tsr_list)} TSRs cargados")
    return tsr_list, datos.get('metadata', {})


def formatear_fuentes(fuentes):
    """Formatea las fuentes bibliogr√°ficas para el prompt"""
    fuentes_texto = []
    
    for i, fuente in enumerate(fuentes, 1):
        autor = fuente.get('autor', 'Autor desconocido')
        titulo = fuente.get('titulo', 'Sin t√≠tulo')
        a√±o = fuente.get('a√±o', 'S/F')
        bloque = fuente.get('bloque', 'Sin clasificar')
        
        fuentes_texto.append(
            f"[{i}] {autor} ({a√±o}): {titulo} [{bloque}]"
        )
    
    return "\n".join(fuentes_texto)


def generar_resumen(tsr):
    """Genera resumen conceptual para un TSR usando Perplexity"""
    numero_tsr = tsr.get('tsr', 'N/A')
    titulo = tsr.get('titulo', 'Sin t√≠tulo')
    cluster = tsr.get('cluster', 'Sin cluster')
    fuentes = tsr.get('fuentes', [])
    
    # Formatear fuentes
    fuentes_texto = formatear_fuentes(fuentes)
    
    # Construir prompt
    prompt = PROMPT_TEMPLATE.format(
        numero_tsr=numero_tsr,
        titulo=titulo,
        cluster=cluster,
        fuentes=fuentes_texto
    )
    
    # Llamada a API
    try:
        response = client.chat.completions.create(
            model=MODELO,
            messages=[
                {
                    "role": "system",
                    "content": "Eres un te√≥rico literario especializado en teor√≠a cr√≠tica contempor√°nea. Redactas res√∫menes densos y precisos con vocabulario acad√©mico."
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            max_tokens=MAX_TOKENS,
            temperature=TEMPERATURA
        )
        
        resumen = response.choices[0].message.content.strip()
        
        # Contar palabras
        num_palabras = len(resumen.split())
        
        return {
            "resumen": resumen,
            "num_palabras": num_palabras,
            "exito": True
        }
    
    except Exception as e:
        return {
            "resumen": None,
            "error": str(e),
            "exito": False
        }


# ============================================================================
# EJECUCI√ìN PRINCIPAL
# ============================================================================

def main():
    print("=" * 80)
    print("üìù CAPA 2: RES√öMENES CONCEPTUALES")
    print("=" * 80)
    print(f"üìÇ Carpeta de trabajo: {os.getcwd()}")
    
    # Cargar TSRs
    tsr_list, metadata_original = cargar_tsr_capa1()
    
    print(f"\nüéØ TSRs a procesar: {len(tsr_list)}")
    print(f"üìä Costo estimado: ${len(tsr_list) * 0.004:.2f} USD")
    print(f"‚è±Ô∏è  Tiempo estimado: ~{len(tsr_list) * 6 // 60 + 1} minutos")
    
    input("\nüöÄ Presiona ENTER para comenzar...")
    
    # Procesar TSRs
    resultados = []
    exitosos = 0
    fallidos = 0
    
    print("\n" + "=" * 80)
    
    for i, tsr in enumerate(tsr_list, 1):
        numero_tsr = tsr.get('tsr', 'N/A')
        titulo = tsr.get('titulo', 'Sin t√≠tulo')
        
        print(f"\nüìö [{i}/{len(tsr_list)}] TSR{numero_tsr}: {titulo}")
        print(f"   üìñ Fuentes: {len(tsr.get('fuentes', []))}")
        
        # Generar resumen
        resultado = generar_resumen(tsr)
        
        if resultado['exito']:
            print(f"   ‚úÖ {resultado['num_palabras']} palabras")
            
            resultados.append({
                "tsr": numero_tsr,
                "titulo": titulo,
                "cluster": tsr.get('cluster', 'Sin cluster'),
                "resumen": resultado['resumen'],
                "num_palabras": resultado['num_palabras'],
                "num_fuentes_usadas": len(tsr.get('fuentes', [])),
                "fecha_generacion": datetime.now().isoformat()
            })
            
            exitosos += 1
        else:
            print(f"   ‚ùå Error: {resultado.get('error', 'Desconocido')}")
            fallidos += 1
        
        # Delay
        if i < len(tsr_list):
            print(f"   ‚è≥ Pausa {DELAY_SEGUNDOS}s...")
            time.sleep(DELAY_SEGUNDOS)
    
    # ========================================================================
    # GUARDAR
    # ========================================================================
    
    print("\n" + "=" * 80)
    print("üíæ GUARDANDO")
    print("=" * 80)
    
    total_palabras = sum(r['num_palabras'] for r in resultados)
    promedio = total_palabras / len(resultados) if resultados else 0
    
    datos_salida = {
        "metadata": {
            "capa": "CAPA 2: Res√∫menes Conceptuales",
            "fecha_generacion": datetime.now().isoformat(),
            "total_tsr": len(resultados),
            "exitosos": exitosos,
            "fallidos": fallidos,
            "tasa_exito": f"{(exitosos/len(tsr_list)*100):.1f}%",
            "total_palabras": total_palabras,
            "promedio_palabras_tsr": round(promedio, 1),
            "modelo": MODELO,
            "archivo_origen": ARCHIVO_ENTRADA
        },
        "resultados": resultados
    }
    
    with open(ARCHIVO_SALIDA, 'w', encoding='utf-8') as f:
        json.dump(datos_salida, f, indent=2, ensure_ascii=False)
    
    # ========================================================================
    # RESUMEN
    # ========================================================================
    
    print("\n" + "=" * 80)
    print("üéâ CAPA 2 COMPLETADA")
    print("=" * 80)
    print(f"\nüìÅ {ARCHIVO_SALIDA}")
    print(f"\nüìä Estad√≠sticas:")
    print(f"   ‚Ä¢ TSRs procesados: {len(tsr_list)}")
    print(f"   ‚Ä¢ Exitosos: {exitosos}")
    print(f"   ‚Ä¢ Fallidos: {fallidos}")
    print(f"   ‚Ä¢ Tasa √©xito: {(exitosos/len(tsr_list)*100):.1f}%")
    print(f"   ‚Ä¢ Palabras totales: {total_palabras:,}")
    print(f"   ‚Ä¢ Promedio: {promedio:.1f} palabras/TSR")
    print(f"   ‚Ä¢ Rango objetivo: 150-200 palabras")
    print("\n" + "=" * 80)
    print("‚úÖ Listo para CAPA 3")
    print("=" * 80)


if __name__ == "__main__":
    main()
